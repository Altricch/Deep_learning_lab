# -*- coding: utf-8 -*-
"""DLL_Assignment1_final_19thOCT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X9z5VCY_aQk8bHXcIVcRDZo87gr6AF5W
"""

import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn 
import torch.optim as optim

# ______________________________________________________________________________
# QUESTION 1.1

def plot_polynomial(coeffs, z_range ,color='b'):
  z = np.linspace(z_range[0], z_range[1], 100)
  y = np.polynomial.polynomial.polyval(z, coeffs)

  fig0, aPN = plt.subplots()
  aPN.plot(z, y, "-")
  aPN.set_xlabel("x", fontsize=16) 
  aPN.set_ylabel("y", fontsize=16)
  aPN.set_title("Polynom Visualization", fontsize = 20)
  
coeff = np.array([0,-5,2,1,0.05])
plot_polynomial(coeff, [-3, 3], color='b')

def dl_gradient_descent(learning_rate_input, iterations_input, train_size, val_size): 
    
  # ______________________________________________________________________________
  # QUESTION 1.2

  def create_dataset(w, z_range , sample_size , sigma, seed=42):
    # ””” Incomplete documentation . ”””
    random_state = np.random.RandomState(seed)
    z = random_state.uniform(z_range[0], z_range[1], sample_size) 
    x = np.zeros((sample_size , w.shape[0]))
    for i in range(sample_size):
      # for j in range ... TODO complete 
      for j in range(w.shape[0]):  
        
      # x[i,j]=... TODOcomplete
        x[i,j] = z[i]**j
    y = x.dot(w) 
    if sigma > 0:
      y += random_state.normal(0.0 , sigma , sample_size) 
    return x, y

  # ______________________________________________________________________________
  # QUESTION 1.3

  # training size 
  t_size = train_size

  # validation size
  size = val_size
  x_interval = (-3,3)
  sigma = 0.5
  seed_training = 0
  seed_validation = 1

  w = np.array([0,-5,2,1,0.05])

  X,y = create_dataset(w,x_interval,t_size, sigma, seed_training)
  X_val,y_val = create_dataset(w, x_interval, size, sigma, seed_validation)


  # ______________________________________________________________________________
  # Question 1.4

  # Training set: 
  fig, train = plt.subplots()
  train.plot(X[:,1],y,"b,")
  train.set_xlabel("x", fontsize = 20)
  train.set_ylabel("y", fontsize = 20)
  train.set_title(f"Training data set visualization, Nr. of sampels: {size}")
  plt.xlim(-3, 3)
  plt.show()
  
  # Validation set: 
  figv, val = plt.subplots()
  plt.plot(X_val[:,1],y_val,"b,")
  val.set_xlabel("x", fontsize = 20)
  val.set_ylabel("y", fontsize = 20)
  val.set_title(f"Validation data set visualization, Nr. of samples: {size}")
  plt.xlim(-3, 3)
  plt.show()

  # ______________________________________________________________________________
  # Question 1.6

  # To set the device dynamically in your code
  DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

  # need linear model where w in R and b in R for f(x) = w * x + b with torch.nn.linear
  model = nn.Linear(5, 1, False) 
  # print("Weight is", model.weight)

  # measures the mean squared error (squared L2 norm) between each element in the input x and target y.
  loss_fn = nn.MSELoss() 

  #learning rate 
  learning_rate = learning_rate_input

  # SGD implements stochastic gradient descent (optionally with momentum) which is our optimizer.
  optimizer = optim.SGD(model.parameters(), lr=learning_rate)

  # Shape expected by nn.Linear
  X = X.reshape(t_size, 5)
  # Convert to torch.tensor
  X = torch.from_numpy(X)
  # Convert to float32 (from numpy double) 
  X = X.float()
  # Copy data to GPU
  X = X.to(DEVICE)

  # Shape expected by nn.Linear
  y = y.reshape(t_size, 1)
  # Convert to torch.tensor
  y = torch.from_numpy(y)
  # Convert to float32 (from numpy double) 
  y = y.float()
  # Copy data to GPU
  y = y.to(DEVICE)

  # Same for other validation variables:
  X_val = torch.from_numpy(X_val.reshape((size, 5))).float().to(DEVICE)
  y_val = torch.from_numpy(y_val.reshape((size, 1))).float().to(DEVICE)

  # For question 1.8
  training_loss_list = []
  validation_loss_list = []
  w_evolution0 = []
  w_evolution1 = []
  w_evolution2 = []
  w_evolution3 = []
  w_evolution4 = []
  num_steps = iterations_input 

  # print("model weight before entering", model.weight.detach().numpy()) # For Exercise 1.7

  # Run the training loop:
  for step in range(num_steps):
    model.train()                 # systematic: put model in ’training’ mode. 
    optimizer.zero_grad()         # systematic: start step w/ zero gradient.
    y_ = model(X)                 # do prediction using the current model.
    loss = loss_fn(y_, y)         # compute error.
    training_loss_list.append(loss) # for exercise 1.10
    loss.backward() # compute gradients. 
    optimizer.step() # update parameters

    # Eval on validation set
    model.eval() # systematic: put model in ’eval’ mode.

    # for exercise 1.11
    w_evolution0.append(model.weight.cpu().detach().numpy()[0][0])
    w_evolution1.append(model.weight.cpu().detach().numpy()[0][1])
    w_evolution2.append(model.weight.cpu().detach().numpy()[0][2])
    w_evolution3.append(model.weight.cpu().detach().numpy()[0][3])
    w_evolution4.append(model.weight.cpu().detach().numpy()[0][4])

    # everything below does not contribute to gradient computation
    with torch.no_grad(): 
      y_ = model(X_val)
      val_loss = loss_fn(y_, y_val) 
      validation_loss_list.append(val_loss) # for exersice 1.10

    # to keep track of loss & val_loss for the threshold to be under 0.06
    if loss <= 0.6 and val_loss <= 0.6:
      # break out of the loop if the increase in iterations leads to an increase in val_loss or loss. Thus, if the gradient overshot.
      if training_loss_list[step-2] < training_loss_list[step-1] or validation_loss_list[step-2] < validation_loss_list[step-1]:
        iterations_input = step+1
        # print("finished at iteration: ", step)
        break

  w_training = model.weight.detach().numpy()
  # print("Converging to weight: ", w_training)

  # Plot the resulting model:
  model.eval()
  with torch.no_grad():
    y_ = model(X)


  # Plot
  fig, ax = plt.subplots()
  ax.plot(X.cpu().numpy()[:,1], y.cpu().numpy(), ".") 
  ax.plot(X.cpu().numpy()[:,1], y_.cpu().numpy(), ".")
  ax.set_xlabel("x", fontsize=16) 
  ax.set_ylabel("y", fontsize=16)
  ax.set_title("Training vs. validation model", fontsize = 20)
  ax.legend(["Training", "Validation"])

  # Training and validation losses:

  out_t_loss = torch.stack(training_loss_list).cpu().detach().numpy()
  out_v_loss = torch.stack(validation_loss_list).cpu().detach().numpy()

  # ______________________________________________________________________________
  # Question 1.8

  fig2, aT = plt.subplots()
  aT.plot(range(iterations_input), out_t_loss, "-") 
  aT.set_xlabel("x", fontsize=16) 
  aT.set_ylabel("y", fontsize=16)
  aT.set_title("Training loss evolution", fontsize = 20)


  fig3, aV = plt.subplots()
  aV.plot(range(iterations_input), out_v_loss, "-")
  aV.set_xlabel("x", fontsize=16) 
  aV.set_ylabel("y", fontsize=16)
  aV.set_title("Validation loss evolution", fontsize = 20)


  # ______________________________________________________________________________
  # Question 1.11
  fig4, wEv = plt.subplots()
  wEv.plot(range(iterations_input), w_evolution0, "-")
  wEv.plot(range(iterations_input), w_evolution1, "-")
  wEv.plot(range(iterations_input), w_evolution2, "-")
  wEv.plot(range(iterations_input), w_evolution3, "-")
  wEv.plot(range(iterations_input), w_evolution4, "-")
  wEv.set_xlabel("x", fontsize=16) 
  wEv.set_ylabel("y", fontsize=16)
  wEv.set_title("Evolution of each coefficient", fontsize = 20)
  wEv.legend(["coeff0", "coeff1", "coeff2", "coeff3", "coeff4"])

  return w_training

dl_gradient_descent(0.0012, 2000, 500, 500)

# ______________________________________________________________________________
# Question 1.7

# dl_gradient_descent(0.004, 5000, 500, 500) naan
# dl_gradient_descent(0.0001, 5000, 500, 500) # not good enough
# dl_gradient_descent(0.0005, 5000, 500, 500) # not good enough
# dl_gradient_descent(0.0008, 2000, 500, 500) # not good enough
# dl_gradient_descent(0.001, 2000, 500, 500) # not good enough

# optimal results achieved at:
# dl_gradient_descent(0.0012, 2000, 500, 500) 


# ______________________________________________________________________________
# Question 1.9
size = 500
iterations = 2000
w_training = dl_gradient_descent(0.0012, iterations, size, size)
# print("1.9", w_training[0])
coeffs = []
for element in w_training[0]:
  coeffs.append(element)
plot_polynomial(coeffs, [-3, 3], color='b')

# ______________________________________________________________________________
# Question 1.10
dl_gradient_descent(0.0012, 2000, 10, 500)

