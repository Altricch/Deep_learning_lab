# -*- coding: utf-8 -*-
"""Christian_Altrichter_DLL_Assignment2_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AVq6IDciultR-7pGACYI5LR3_mXsIlno
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision 
import torchvision.transforms as transforms
import torch.utils.data as data

import numpy as np
import matplotlib.pyplot as plt

torch.__version__

torch.manual_seed(0)
np.random.seed(0)

if torch.cuda.is_available():
    torch.cuda.manual_seed_all(0)
    # torch.backends.cudnn.deterministic = True

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ______________________________________________________________________________
# QUESTION 1.1.1

batch_size = 32

# Training and test set (not normalized)
train_set = torchvision.datasets.CIFAR10(
    root='./data', train=True, transform=transforms.ToTensor(), download=True)

test_set = torchvision.datasets.CIFAR10(
    root='./data', train=False,transform=transforms.ToTensor())

# Dataloader(s)
train_loader = torch.utils.data.DataLoader(
    dataset=train_set, batch_size = batch_size, shuffle=False)

test_loader = torch.utils.data.DataLoader(
    dataset=test_set, batch_size = batch_size, shuffle=False)

# Image classifications
image_classifications_list = ["plane", "car", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]

# Display of 4 Images
fig = plt.figure(figsize=(128, 128))
images, labels = next(iter(train_loader))

for i in range(1,5):
  img = images[i]
  lab = labels[i]
  print("lab is", lab.numpy())
  lab = image_classifications_list[lab.numpy()]
  f = fig.add_subplot(32,32,i)
  f.set_title(lab, fontsize = 16)
  f.set_xlabel("32 pixels", fontsize=12) 
  f.set_ylabel("32 pixels", fontsize=12) 
  plt.imshow(transforms.ToPILImage()(img))
  plt.subplots_adjust(left=3.0,
                    bottom=3.0,
                    right=4.0,
                    top=4.0)


# ____________________________________________________________________________
# QUESTION 1.1.2

transform = transforms.Compose([transforms.ToTensor(),
                              transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),
                             ])

# Normalied data sets
train_set_norm = torchvision.datasets.CIFAR10(
    root='./data', train=True, transform=transform, download=True)

test_set_norm = torchvision.datasets.CIFAR10(
    root='./data', train=False,transform=transform)

# Dataloaders

test_loader_norm = torch.utils.data.DataLoader(
    dataset=test_set_norm, batch_size = batch_size, shuffle=False)

train_loader_norm = torch.utils.data.DataLoader(
    dataset=train_set_norm, batch_size = batch_size, shuffle=False)


# ____________________________________________________________________________
# QUESTION 1.1.3

given_mean = [0.4914, 0.4822, 0.4465]
given_std = [0.247, 0.243, 0.261]


def mean_and_std(data_loader):
    count = 0
    mean = torch.tensor([0., 0., 0.])
    variance = torch.tensor([0., 0., 0.])

    for images, _ in data_loader:
        b, c, h, w = images.shape
        pixels = b * h * w
        sum_ = torch.sum(images, dim=[0, 2, 3])
        sum_of_square = torch.sum(images ** 2,
                                  dim=[0, 2, 3])
        mean = (count * mean + sum_) / (count + pixels)
        variance = (count * variance + sum_of_square) / (count + pixels)
        count += pixels

    mean, std = mean, torch.sqrt(variance - mean ** 2)   
    mean = mean.numpy()
    std = std.numpy()

    for i in range(len(mean)):
      mean[i] = round(mean[i], 4)
      std[i] = round(std[i], 3)

      mean_check = round(mean[i] - round(given_mean[i],4),3)
      std_check = round(std[i] - round(given_std[i],3),3)

      if mean_check != 0 or std_check != 0:
        print("Mean and std not properly calculated, pls fix")
      else:
        print("Mean and std properly calculated")
    return mean,std
  
mean, std = mean_and_std(train_loader)
print("mean and std: \n", mean, std)

  
mean_norm, std_norm = mean_and_std(train_loader_norm)
print("mean and std: \n", mean_norm, std_norm)


# # ____________________________________________________________________________
# # QUESTION 1.1.4

train_size = 49000
valid_size = 1000

train_set, valid_set = data.random_split(train_set, [train_size, valid_size])
train_set_norm, valid_set_norm = data.random_split(train_set_norm, [train_size, valid_size])

print('NEW Train data set:', len(train_set_norm))
print('NEW Val data set:', len(valid_set_norm))

# Dataloaders for new training
train_loader_norm = torch.utils.data.DataLoader(
    dataset=train_set_norm, batch_size = batch_size, shuffle=False)

# Dataloaders for new valdiation
valid_loader_norm = torch.utils.data.DataLoader(
    dataset=valid_set_norm, batch_size = batch_size, shuffle=False)

valid_loader = torch.utils.data.DataLoader(
    dataset=valid_set, batch_size = batch_size, shuffle=False)

# # ____________________________________________________________________________
# # QUESTION 1.2.1

def image_classification(learning_rate, momentum, epochs, dropout_value):
  class ConvolutionalModel(nn.Module):
      def __init__(self, num_classes):
        super(ConvolutionalModel, self).__init__()
        self.cv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), padding=(1,1))
        self.cv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), padding=(1,1))
        self.cv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=(1,1))
        self.cv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding=(1,1))
        self.pool = nn.MaxPool2d(2,2)
        self.fc1 = nn.Linear(in_features=8*8*64, out_features=512)
        self.DP1 = nn.Dropout(dropout_value)
        self.fc2 = nn.Linear(in_features=512, out_features = num_classes)

      # Relu changed to gelu for 1.3.7!
      def forward(self, x): 
        x = F.gelu(self.cv1(x)) 
        x = F.gelu(self.cv2(x)) 
        x = self.pool(x) 
        x = self.DP1(x)
        x = F.gelu(self.cv3(x)) 
        x = F.gelu(self.cv4(x)) 
        x = self.pool(x) 
        x = self.DP1(x)
        x = x.view(-1, 8*8*64) 
        x = F.gelu(self.fc1(x))
        x = self.fc2(x)
        return x

  # ____________________________________________________________________________
  # QUESTION 1.3.1 (partially) & 1.3.2

  num_classes = 10

  model = ConvolutionalModel(num_classes)
  model = model.to(device)  # put all model params on GPU.

  # Create loss and optimizer
  loss_fn = nn.CrossEntropyLoss() # for 1.3.2
  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)


  # ____________________________________________________________________________
  # QUESTION 1.3.1 

  # Training

  best_validation_accuracy = (0,0)

  # Specifically for 1.3.1
  n = 200

  # For 1.3.4
  loss_evolution_train = []
  accuracy_evolution_train = []
  loss_evolution_valid = []
  accuracy_evolution_valid = []

  for epoch in range(1, epochs+1):
      running_loss = 0.0
      running_total = 0
      running_correct = 0
      run_step = 0
      for i, (images, labels) in enumerate(train_loader_norm):
          model.train()  
          images = images.to(device)
          labels = labels.to(device)  
          outputs = model(images)  
          loss = loss_fn(outputs, labels)
          optimizer.zero_grad()  
          loss.backward()  
          optimizer.step() 

          running_loss += loss.item()
          running_total += labels.size(0)

          with torch.no_grad():
              _, predicted = outputs.max(1)
          running_correct += (predicted == labels).sum().item()
          run_step += 1
          if i % n == 0:
              # for 1.3.5
              loss_evolution_train.append(running_loss / run_step)
              accuracy_evolution_train.append(100 * running_correct / running_total)
              # check accuracy.
              print(f'epoch: {epoch}, steps: {i}, '
                    f'train_loss: {running_loss / run_step :.3f}, '
                    f'running_acc: {100 * running_correct / running_total:.1f} %')
              running_loss = 0.0
              running_total = 0
              running_correct = 0
              run_step = 0

      # validation
      correct = 0
      total = 0
      model.eval()
      with torch.no_grad():
          for data in valid_loader_norm:
              images, labels = data
              images, labels = images.to(device), labels.to(device)
              outputs = model(images)
              _, predicted = outputs.max(1)
              total += labels.size(0)
              correct += (predicted == labels).sum().item()
              val_acc = 100 * correct / total

              # For 1.3.4   
              val_loss = loss_fn(outputs, labels)
              loss_evolution_valid.append(val_loss.item())
              accuracy_evolution_valid.append(val_acc)
     
      # For 1.3.1 to keep track of best validation accuracy
      if best_validation_accuracy[0] < val_acc:
        best_validation_accuracy = val_acc, epoch   
      # NB: : .1f specifies that you want 1 floating point
      print(f'Validation accuracy: {100 * correct / total: .1f} %')
      # TODO: you need to add code to keep track of the best so-far validation
      # accuracy, and the corresponding model parameters.
  print("best validation accuracy is:", best_validation_accuracy) 
  print('Finished Training')

  # Evaluation
  with torch.no_grad():
      correct = 0
      total = 0
      model.eval() # Set model in eval mode. Donâ€™t forget!
      for data in test_loader_norm:
          images, labels = data
          images = images.to(device)
          labels = labels.to(device) 
          outputs = model(images) 
          _, predicted = outputs.max(dim=1)
          total += labels.size(0)
          correct += (predicted == labels).sum().item()
      test_acc = 100 * correct / total
      print(f'Test accuracy: {test_acc} %')
      print(f'Test error rate: {100 - 100 * correct / total: .2f} %')

  return model, loss_evolution_valid, accuracy_evolution_valid, loss_evolution_train, accuracy_evolution_train

model, loss_ev_val, acc_ev_val, loss_ev_train, acc_ev_train = image_classification(0.001, 0.9, 20, 0)

# ____________________________________________________________________________
# QUESTION 1.3.4


def plot_loss_and_acc(val_acc, val_loss, train_acc, train_loss):
  # Adjustment for training data
  step = len(train_loss) / 20
  run_loss = train_loss[0]
  run_acc = train_acc[0]
  out_loss_train = []
  out_acc_train = []

  # Loss
  for i in range(1,len(train_loss)):
    if i == 0:
      continue
    if i % step == 0:
      out_loss_train.append(run_loss / step)
      run_loss = 0

    run_loss += train_loss[i]

  out_loss_train.append(run_loss / step) 

  # Accuracy
  for i in range(1, len(train_acc)):
    if i == 0:
      continue
    if i % step == 0:
      out_acc_train.append(run_acc / step)
      run_acc = 0

    run_acc +=  train_acc[i]

  out_acc_train.append(run_acc / step)

  # Adjustment for validation data (size 640)
  step_val = len(val_loss) / 20
  run_loss_val = val_loss[0]
  run_acc_val = val_acc[0]
  out_loss_val = []
  out_acc_val = []

  # Loss
  for i in range(1,len(val_loss)):
    if i == 0:
      continue
    if i % step_val == 0:
      out_loss_val.append(run_loss_val / step_val)
      run_loss_val = 0

    run_loss_val += val_loss[i]

  out_loss_val.append(run_loss_val / step_val) 

  # Accuracy
  for i in range(1, len(val_acc)):
    if i == 0:
      continue
    if i % step_val == 0:
      out_acc_val.append(run_acc_val / step_val)
      run_acc_val = 0

    run_acc_val +=  val_acc[i]

  out_acc_val.append(run_acc_val / step_val)

  # Loss evolution
  fig, loss = plt.subplots()
  loss.plot(range(0, len(out_loss_val)),out_loss_val,"-")
  loss.plot(range(0,len(out_loss_train)), out_loss_train, "-")
  loss.set_xlabel("Iteration count", fontsize = 16)
  loss.set_ylabel("Loss", fontsize = 16)
  loss.set_title(f"Loss comparison between training and validation sets")
  loss.legend(["Validation set loss", "Training set loss"])
  plt.show()

  # accuracy evolution
  fig, acc = plt.subplots()
  acc.plot(range(0, len(out_acc_val)),out_acc_val,"-")
  acc.plot(range(0,len(out_acc_train)), out_acc_train, "-")
  acc.set_xlabel("Iteration count", fontsize = 16)
  acc.set_ylabel("Accuracy", fontsize = 16)
  acc.set_title(f"Accuracy comparison between training and validation sets")
  acc.legend(["Validation set accuracy", "Training set accuracy"])
  plt.show()


plot_loss_and_acc(acc_ev_val, loss_ev_val, acc_ev_train, loss_ev_train)

# ____________________________________________________________________________
# QUESTION 1.3.5

# Dropout 0.2
model02, loss_ev_val2, acc_ev_val2, loss_ev_train2, acc_ev_train2 = image_classification(0.001, 0.9, 20, 0.2)
plot_loss_and_acc(acc_ev_val2, loss_ev_val2, acc_ev_train2, loss_ev_train2)

# Dropout 0.5
model05,loss_ev_val5, acc_ev_val5, loss_ev_train5, acc_ev_train5 = image_classification(0.001, 0.9, 20, 0.5)
# plot_loss_and_acc(acc_ev_val5, loss_ev_val5, acc_ev_train5, loss_ev_train5)

# Dropout 0.8
model08, loss_ev_val8, acc_ev_val8, loss_ev_train8, acc_ev_train8 = image_classification(0.001, 0.9, 20, 0.8)
plot_loss_and_acc(acc_ev_val8, loss_ev_val8, acc_ev_train8, loss_ev_train8)

# ____________________________________________________________________________
# QUESTION 1.3.6 (with non normalized images)

from numpy.ma.core import maximum_fill_value



# Images:
images_for_dist = []
labels_for_dist = []

# Image display of 4 images:
fig = plt.figure(figsize=(128, 128))
images, labels = next(iter(valid_loader))
images2, labels2 = next(iter(valid_loader_norm))

for i in range(1,11):
  img = images[i]
  lab = labels[i]
  lab = image_classifications_list[lab.numpy()]
  images_for_dist.append(img.numpy())
  labels_for_dist.append(lab)
  f = fig.add_subplot(32,32,i)
  f.set_title(lab, fontsize = 16)
  f.set_xlabel("32 pixels", fontsize=12) 
  f.set_ylabel("32 pixels", fontsize=12) 
  plt.imshow(transforms.ToPILImage()(img))
  plt.subplots_adjust(left=3.0,
                    bottom=3.0,
                    right=4.0,
                    top=4.0)


print(len(images_for_dist))

im = torch.tensor(images_for_dist).to(device)
output = model05(im)
probability = nn.Softmax()(output)
rdProbability = np.round_(probability.detach().cpu().numpy(),3)

print(rdProbability)


# populate max index
maxIndexes = []
for i in range(0,len(rdProbability)):
  maxI = 0
  for j in range(0,10):
    if rdProbability[i][j] > rdProbability[i][maxI]:
      maxI = j
  maxIndexes.append(maxI)

print(maxIndexes)

for i in range(len(maxIndexes)):
  print(image_classifications_list[maxIndexes[i]])

# ____________________________________________________________________________
# QUESTION 1.3.6 (with normalized images)

from numpy.ma.core import maximum_fill_value

# Images:
images_for_dist = []
labels_for_dist = []

# Image display of 4 images:
fig = plt.figure(figsize=(128, 128))
images, labels = next(iter(valid_loader_norm))

for i in range(1,11):
  img = images[i]
  lab = labels[i]
  lab = image_classifications_list[lab.numpy()]
  images_for_dist.append(img.numpy())
  labels_for_dist.append(lab)
  f = fig.add_subplot(32,32,i)
  f.set_title(lab, fontsize = 16)
  f.set_xlabel("32 pixels", fontsize=12) 
  f.set_ylabel("32 pixels", fontsize=12) 
  plt.imshow(transforms.ToPILImage()(img))
  plt.subplots_adjust(left=3.0,
                    bottom=3.0,
                    right=4.0,
                    top=4.0)

print(len(images_for_dist))

im = torch.tensor(images_for_dist).to(device)
output = model05(im)
probability = nn.Softmax()(output)
rdProbability = np.round_(probability.detach().cpu().numpy(),3)

print(rdProbability)


# populate max index
maxIndexes = []
for i in range(0,len(rdProbability)):
  maxI = 0
  for j in range(0,10):
    if rdProbability[i][j] > rdProbability[i][maxI]:
      maxI = j
  maxIndexes.append(maxI)

print(maxIndexes)

for i in range(len(maxIndexes)):
  print(image_classifications_list[maxIndexes[i]])

# ____________________________________________________________________________
# QUESTION 1.3.7

loss_ev_val2, acc_ev_val2, loss_ev_train2, acc_ev_train2 = image_classification(0.01, 0.85, 20, 0.55)
plot_loss_and_acc(acc_ev_val2, loss_ev_val2, acc_ev_train2, loss_ev_train2)